import numpy as np
import quaternion as qt
import scipy.optimize as optimize
from scipy.optimize import Bounds
import cv2
from matplotlib import pyplot as plt
import open3d
from mpl_toolkits.mplot3d import Axes3D


np.set_printoptions(suppress=True,
   formatter={'float_kind':'{:f}'.format})

#GLOBAL VALUES
# K = np.array([[640, 0, 640], [0, 640, 360], [0,0,1]])
K = np.array([[1/640, 0, 1], [0, 640/360, 1], [0,0,1]])
FOV = 90
XRES = 1280
YRES = 720

##############
# Convert to homogeneous points

def convertPoints(pts, alpha, xres, yres):
	#alpha is fov
	length = (np.shape(pts))[0]
	pts = np.subtract(pts1, [XRES/2, YRES/2])

	pts = -pts

	norm = np.matmul(pts, np.array([[1/(xres/np.tan(alpha*(np.pi)/360)), 0],[0, 1/(yres/np.tan(alpha*(np.pi)/360))]]))
	# out = np.ones((3,length))
	# out[:2,:] = np.transpose(norm)

	return np.transpose(norm)


def readFile():

	file = open("../orb/images/airsim_rec.txt","r") # Reads the file generated by airSim with location + qt rotation

	params = np.empty((0,7))

	images = []

	for line in file:
		fields = line.split()
		images.append(fields[8]) #append image file name
		params = np.vstack((params, np.array(fields[1:8]))) # append the location + qt rotation info for each image

	return params.astype(np.float), images


def orbDetect (file1, file2):

    img2 = cv2.imread('../orb/images/' + file1, 0) # get the previous image
    img1 = cv2.imread('../orb/images/' + file2, 0) # get the current image

    # Initiate SIFT detector
    orb = cv2.ORB_create(10000)

    # find the keypoints and descriptors with SIFT
    kp1, des1 = orb.detectAndCompute(img1, None)
    kp2, des2 = orb.detectAndCompute(img2, None)

    # create BFMatcher object
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)


    matches = bf.knnMatch(des1,des2, k=2)

    good = [] # good stores the good matches
    pts1 = [] # pts 1 contains where the points in the match are in img1
    pts2 = [] # pts 2 contains where the points in the match are in img2

    # Uses Hamming distance to filter out bad matches between the 2 images.

    for (m,n) in matches:

        good.append(m)
        pts2.append(kp2[m.trainIdx].pt)
        pts1.append(kp1[m.queryIdx].pt)


    pts1 = np.int32(pts1)
    pts2 = np.int32(pts2)

    return pts1, pts2, img1, img2


def process(params):
	prev = params[0] # gets loc + qt from the info of previous img
	cur = params[1] # gets loc + qt from the info of previous img



	### My Coords: x, y, z => AIRSIM Coords: z, x, y
	# stores the translation to get from current img to the prev imag
	trans = [0,0,0]
	trans[:2] = -cur[1:3] + prev[1:3] # rearranging coords from airSim
	trans[2] = -cur[0] + prev[0] #rearranging coords from airSIm

	currot = [0,0,0,0] # rearranging coords from airSim
	prevrot = [0,0,0,0]
	currot[0] = cur[3]
	currot[3] = cur[4]
	currot[1:3] = cur[5:7]
	prevrot[0] = prev[3]
	prevrot[3] = prev[4]
	prevrot[1:3] = prev[5:7]
	prevrot = qt.as_rotation_matrix(qt.as_quat_array(prevrot)) # qt to rotation matrix
	currot = qt.as_rotation_matrix(qt.as_quat_array(currot))

	rot = np.matmul(currot, np.linalg.inv(prevrot)) # rot prev points to current frames

	return  np.array(trans), rot


def getDepth(pts1, pts2, trans, rot):
	P1 = np.eye(4) # projection matrix for the first img, identity since we are using it as reference
	P1 = P1[:3]
	P2 = np.zeros((3,4)) # projection matrix for the first img, identity since we are using it as reference
	P2[:, :3] = rot
	P2[:, 3] = trans

	pts1_norm = convertPoints(pts1, FOV, XRES, YRES)
	pts2_norm = convertPoints(pts2, FOV, XRES, YRES)

	X = cv2.triangulatePoints( P1, P2, pts1_norm, pts2_norm)
	return X



############################ MAIN #############################################

params, images = readFile()


for i in range(len(images)-1):
	pts1, pts2, img1, img2 = orbDetect(images[i], images[i+1])

	# pts3= convertPoints(pts1, FOV, XRES, YRES)
	# pts4 = convertPoints(pts2, FOV, XRES, YRES)


	trans, rot = process([params[i], params[i+1]])


	res = getDepth(pts1, pts2, trans, rot)
	Points = res[:3]

	print (np.transpose(res))
	Points = Points * 20

	print (images[i+1])

	
	point_cloud = open3d.PointCloud()
	point_cloud.points = open3d.Vector3dVector(np.transpose(Points))


	open3d.draw_geometries([point_cloud])




